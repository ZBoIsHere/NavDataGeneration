## PYTHON 
## ******************************************************************** ##
## author: CTO_TI_FBSYJG
## create time: 2025/09/23 12:03:01 GMT+08:00
## ******************************************************************** ##
from math import dist
import os
import re
import sys
import gzip
import json
import uuid
import argparse

from numpy import integer, short
from sqlalchemy import create_engine, Column, String, Float, Integer, ForeignKey, ARRAY
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy.exc import SQLAlchemyError
from urllib.parse import quote_plus

#os.chdir('/mnt/sfs-turbo-workflow/data-platform/')

# ORM åŸºç±»
Base = declarative_base()

# è¡¨æ¨¡å‹å®šä¹‰
class TaskDatasetObjectNav(Base):
    __tablename__ = "task_datasets_objectnav"
    __table_args__ = {'schema': 'public'}

    id = Column(String(36), primary_key=True)
    scene_type = Column(String(50), nullable=False)
    split = Column(String(10), nullable=False)
    scene_name = Column(String(255), nullable=False)
    object_category = Column(String(255), nullable=False)
    geodesic_distance = Column(Float, nullable=False)
    euclidean_distance = Column(Float, nullable=False)
    nav_complexity_ratio = Column(Float, nullable=False)
    recipe_tags = Column(ARRAY(String), default=[])

class TrajDatasetObjectNav(Base):
    __tablename__ = "traj_datasets_objectnav"
    __table_args__ = {'schema': 'public'}

    id = Column(String(36), primary_key=True)                     # å”¯ä¸€è½¨è¿¹ID
    gen_traj_method = Column(String(50), nullable=False)          # è½¨è¿¹ç”Ÿæˆæ–¹æ³•
    task_id = Column(String(36), nullable=False)  # å…³è”ä»»åŠ¡ID
    success = Column(Integer, nullable=False)                     # æ˜¯å¦æˆåŠŸå®Œæˆä»»åŠ¡
    spl = Column(Float)                                           # SPLæŒ‡æ ‡
    dist2goal = Column(Float)                                           # åˆ°ç›®æ ‡çš„è·ç¦»
    traj_len = Column(Integer)                                      # è½¨è¿¹é•¿åº¦
    experiment_name = Column(String(255))                         # å®éªŒåç§°
    # æ·»åŠ ä¸€ä¸ªrecipe_tagså­—æ®µï¼Œç±»å‹ä¸ºARRAY(String)ï¼Œé»˜è®¤å€¼ä¸ºç©ºåˆ—è¡¨
    recipe_tags = Column(ARRAY(String), default=[])

# UUID ç”Ÿæˆé€»è¾‘
def generate_task_uuid(scene_type, scene_name, split, start_position, start_rotation, object_category):
    namespace = uuid.NAMESPACE_DNS
    key = f"{scene_type}:{scene_name}:{split}:{start_position}:{start_rotation}:{object_category}"
    return str(uuid.uuid5(namespace, key))

# UUID ç”Ÿæˆé€»è¾‘
def generate_traj_uuid(scene_type, scene_name, split, start_position, start_rotation, object_category, gen_traj_method, experiment_name):
    namespace = uuid.NAMESPACE_DNS
    key = f"{scene_type}:{scene_name}:{split}:{start_position}:{start_rotation}:{object_category}:{gen_traj_method}:{experiment_name}"
    return str(uuid.uuid5(namespace, key))

# æŸ¥æ‰¾ JSON.GZ æ–‡ä»¶
def find_json_gz_file(dataset_path, scene_name):
    for filename in os.listdir(dataset_path):
        if filename.startswith(scene_name) and filename.endswith(".json.gz"):
            return os.path.join(dataset_path, filename)
    return None

def gen_record(args, ep):
    record = None

    start_position = ep["start_position"]
    start_rotation = ep["start_rotation"]
    object_category = ep["object_category"]
    info = ep["info"]

    if args.dataset_type == "task_datasets":
        task_id = generate_task_uuid(
            args.scene_type, args.scene_name, args.split,
            start_position, start_rotation, object_category
        )

        record = TaskDatasetObjectNav(
            id=task_id,
            scene_type=args.scene_type,
            split=args.split,
            scene_name=args.scene_name,
            object_category=object_category,
            geodesic_distance=info["geodesic_distance"],
            euclidean_distance=info["euclidean_distance"],
            nav_complexity_ratio=info["geodesic_distance"] / info["euclidean_distance"]
            if info["euclidean_distance"] != 0 else 0,
            recipe_tags=[args.recipe_tag]
        )
    elif args.dataset_type == "traj_datasets":
        task_id = generate_task_uuid(
            args.scene_type, args.scene_name, args.split,
            start_position, start_rotation, object_category
        )

        traj_id = generate_traj_uuid(
            args.scene_type, args.scene_name, args.split,
            start_position, start_rotation, object_category,
            args.gen_traj_method, args.experiment_name
        )

        metrics = ep.get("metrics", {})
        if not metrics:
            print("âš ï¸ è­¦å‘Š: è¯¥ episode ç¼ºå°‘ metrics ä¿¡æ¯ï¼Œè·³è¿‡è¯¥è®°å½•")
            return None

        record = TrajDatasetObjectNav(
            id=traj_id,
            gen_traj_method=args.gen_traj_method,
            task_id=task_id,
            success=metrics.get("success", 0),
            spl=metrics.get("spl", 0.0),
            dist2goal=metrics.get("distance_to_goal", 0.0),
            traj_len=metrics.get("traj_len", 0),
            experiment_name=args.experiment_name,
            recipe_tags=[args.recipe_tag]
        )

    return record

def precheck_args(args):
    invalid_args = []
    if args.dataset_type not in ["task_datasets", "traj_datasets"]:
        print(f"âŒ å‚æ•° dataset_type {args.dataset_type} å¿…é¡»æ˜¯ 'task_datasets' æˆ– 'traj_datasets'")
        invalid_args.append("dataset_type")
    if not os.path.isdir(args.input_path):
        print(f"âŒ å‚æ•° input_path {args.input_path} æŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {args.input_path}")
        invalid_args.append("input_path")

    from pathlib import Path

    # å¦‚æœdataset_typeæ˜¯task_datasets, input_pathé‡Œé¢å¿…é¡»åŒ…å«task_datasetsæˆ–traj_datasets
    if args.dataset_type == "task_datasets":
        if not any(part in ["task_datasets", "traj_datasets"] for part in Path(args.input_path).parts):
            print(f"âŒ å‚æ•° input_path {args.input_path} è·¯å¾„ä¸­å¿…é¡»åŒ…å« 'task_datasets' æˆ– 'traj_datasets'")
            invalid_args.append("input_path")
    # å¦‚æœdataset_typeæ˜¯traj_datasets, input_pathé‡Œé¢å¿…é¡»åŒ…å«traj
    elif args.dataset_type == "traj_datasets":
        # æ£€æŸ¥ input_path, è·¯å¾„é‡Œå¿…é¡»åŒ…å«trajçš„å­å­—ç¬¦ä¸²
        if not any("traj" in part for part in Path(args.input_path).parts):
            print(f"âŒ å‚æ•° input_path {args.input_path} è·¯å¾„ä¸­å¿…é¡»åŒ…å« 'traj' å­å­—ç¬¦ä¸²")
            invalid_args.append("input_path")

    # å¦‚æœexperiment_nameæ˜¯nullï¼Œè¡¨ç¤ºä¸æ˜¯åŸºäºå®éªŒç”Ÿæˆçš„è½¨è¿¹ï¼Œåˆ™è¿›è¡Œscene_typeæ£€æŸ¥
    if args.experiment_name == "null":
        # ä¿®æ”¹æˆæ£€æŸ¥args.input_pathçš„å­ç›®å½•çš„å­å­—ç¬¦ä¸²åŒ…å«args.scene_type 
        is_scene_type_valid = False
        for part in Path(args.input_path).parts:
            if args.scene_type in part:
                is_scene_type_valid = True
                break
    
        if not is_scene_type_valid:
            print(f"âŒ å‚æ•° input_path {args.input_path} è·¯å¾„ä¸­å¿…é¡»åŒ…å« scene_type çš„å­å­—ç¬¦ä¸²: {args.scene_type}")
            invalid_args.append("input_path")

        # æ£€æŸ¥ input_path, è·¯å¾„é‡Œå¿…é¡»åŒ…å«args.splitçš„å­ç›®å½•   
        if args.split not in Path(args.input_path).parts:
            print(f"âŒ å‚æ•° input_path {args.input_path} è·¯å¾„ä¸­å¿…é¡»åŒ…å« split çš„å­ç›®å½•: {args.split}")
            invalid_args.append("input_path")

        if args.recipe_tag not in Path(args.input_path).parts:
            print(f"âŒ å‚æ•° input_path {args.input_path} è·¯å¾„ä¸­å¿…é¡»åŒ…å« recipe_tag: {args.recipe_tag}")
            invalid_args.append("input_path")

    # æ£€æŸ¥ gen_traj_method, ä»…å½“ dataset_type æ˜¯ traj_datasets æ—¶æ£€æŸ¥
    # input_path é‡Œå¿…é¡»åŒ…å« gen_traj_method çš„å­å­—ç¬¦ä¸²
    if args.dataset_type == "traj_datasets":
        # æ£€æŸ¥input_pathä¸­æ˜¯å¦åŒ…å«content_metrics, å¦‚æœä¸åŒ…å«ï¼Œå°±æç¤ºç”¨æˆ·ä¿®æ”¹ä¸ºcontent_metrics
        if "content_metrics" not in Path(args.input_path).parts:
            print(f"âŒ å‚æ•° input_path {args.input_path} è·¯å¾„ä¸­å¿…é¡»åŒ…å« 'content_metrics' å­ç›®å½•")
            invalid_args.append("input_path")

        if args.gen_traj_method not in args.input_path:
            print(f"âŒ å‚æ•° input_path {args.input_path} è·¯å¾„ä¸­å¿…é¡»åŒ…å« gen_traj_method: {args.gen_traj_method}")
            invalid_args.append("input_path")
        
        # å¦‚æœinput_pathé‡Œé¢åŒ…å«traj_datasetsï¼Œé‚£ä¹ˆexperiment_nameå¿…é¡»ä¸º"null"
        if "traj_datasets" in Path(args.input_path).parts and args.experiment_name != "null":
            print(f"âŒ å‚æ•° experiment_name å¿…é¡»ä¸ºnullï¼Œå› ä¸º input_path {args.input_path} åŒ…å« 'traj_datasets'")
            invalid_args.append("experiment_name")
        # å¦‚æœinput_pathé‡Œé¢ä¸åŒ…å«traj_datasetsï¼Œé‚£ä¹ˆexperiment_nameä¸èƒ½ä¸º"null"
        if "traj_datasets" not in Path(args.input_path).parts and args.experiment_name == "null":
            print(f"âŒ å‚æ•° experiment_name ä¸èƒ½ä¸ºnullï¼Œå› ä¸º input_path {args.input_path} ä¸åŒ…å« 'traj_datasets'")
            invalid_args.append("experiment_name")
        
    # input_path é‡Œå¿…é¡»åŒ…å« recipe_tag
    # æ£€æŸ¥ recipe_tagæ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºï¼Œåˆ™æŠ¥é”™
    if not args.recipe_tag:
        print(f"âŒ å‚æ•° recipe_tag ä¸èƒ½ä¸ºç©ºï¼Œå½“ dataset_type æ˜¯ task_datasets æ—¶å¿…é¡»æä¾›")
        invalid_args.append("recipe_tag")

    return invalid_args

# ä¸»ç¨‹åºé€»è¾‘
def main(args):
    json_path = find_json_gz_file(args.input_path, args.scene_name)
    if not json_path:
        print(f"âŒ æœªæ‰¾åˆ°ä»¥ {args.scene_name} å¼€å¤´çš„ .json.gz æ–‡ä»¶")
        return

    encoded_password = quote_plus(args.db_password)
    db_url = f"postgresql+psycopg2://{args.db_user}:{encoded_password}@{args.db_host}:{args.db_port}/{args.db_name}"
    engine = create_engine(db_url)
    Session = sessionmaker(bind=engine)
    session = Session()
    print(f"ğŸ”— è¿æ¥æ•°æ®åº“ï¼š{db_url}")

    try:
        with gzip.open(json_path, 'rt', encoding='utf-8') as f:
            data = json.load(f)
            episodes = data.get("episodes", [])
            print(f"ğŸ“¦ å…±æ‰¾åˆ° {len(episodes)} ä¸ª episodes")

            count = 0
            for ep in episodes:
                record = gen_record(args, ep)
                # å¦‚æœtask_id æˆ– traj_idå·²ç»å­˜åœ¨ï¼Œå°±åˆå¹¶task_dataset_tasgsæˆ–recipe_tagså­—æ®µï¼Œç„¶åæ›´æ–°è®°å½•
                # tagsè¦æ±‚ä¸é‡å¤

                # æ˜¯å¦æ˜¯é‡å¤è®°å½•
                duplicate = False

                pre_record = None
                if args.dataset_type == "task_datasets" and record:
                    pre_record = session.query(TaskDatasetObjectNav).filter_by(id=record.id).first()
                elif args.dataset_type == "traj_datasets" and record:
                    pre_record = session.query(TrajDatasetObjectNav).filter_by(id=record.id).first()
                if pre_record:
                    # å¦‚æœrecordçš„tagsåœ¨pre_recordçš„tagsé‡Œå·²ç»å­˜åœ¨ï¼Œå°±è·³è¿‡è¯¥episode
                    if record.recipe_tags[0] in pre_record.recipe_tags :
                        print(f"âš ï¸ è®°å½•å·²å­˜åœ¨ä¸” tags ç›¸åŒï¼Œè·³è¿‡è¯¥ episode")
                        duplicate = True
                        if args.force_overwrite == 'True':
                            print(f"âš ï¸ å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨è®°å½•: {record.id}")
                            duplicate = False
                    else:
                        print(f"ğŸ”„ è®°å½•å·²å­˜åœ¨ï¼Œåˆå¹¶ tags: {pre_record.recipe_tags} + {record.recipe_tags}")
                        if pre_record.recipe_tags is None:
                            pre_record.recipe_tags = []
                        merged_tags = list(set(pre_record.recipe_tags + record.recipe_tags))
                        pre_record.recipe_tags = merged_tags
                        record = pre_record
                
                if record and not duplicate:
                    session.merge(record)
                    count += 1
                    if count % 100 == 0:
                        session.commit()
                        print(f"ğŸ’¾ å·²æäº¤ {count} æ¡è®°å½•")
                elif record is None:
                    print("âš ï¸ è®°å½•ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡è¯¥ episode")

            # æäº¤å‰©ä½™æœªæ»¡100æ¡çš„è®°å½•
            if count % 100 != 0:
                session.commit()
                print(f"ğŸ’¾ æœ€åæäº¤å‰©ä½™ {count % 100} æ¡è®°å½•")
            print("âœ… æ•°æ®æ’å…¥å®Œæˆ")
    except SQLAlchemyError as e:
        print(f"âš ï¸ æ•°æ®åº“æ“ä½œå¤±è´¥ï¼š{e}")
        session.rollback()
    except Exception as e:
        print(f"âš ï¸ ç¨‹åºå¼‚å¸¸ï¼š{e}")
    finally:
        session.close()

# argparse å‚æ•°è§£æ
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å¯¼å…¥ ObjectNav ä»»åŠ¡&è½¨è¿¹æ•°æ®é›†åˆ° PostgreSQL æ•°æ®åº“")
    parser.add_argument("--dataset_type", default="traj_datasets", help="task_datasets or traj_datasets")
    parser.add_argument("--input_path", default="data/traj_datasets/objectnav/cloudrobo_v1_l3mvn_all/train/content_metrics", help="æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--scene_name", default="shanghai-lianqiuhu-b11-4f-big-2025-07-15_11-40-37", help="åœºæ™¯åç§°")
    parser.add_argument("--scene_type", default="cloudrobo_v1", help="åœºæ™¯ç±»å‹")
    parser.add_argument("--split", default="train", help="æ•°æ®é›†åˆ’åˆ†ç±»å‹")
    # æ•°æ®é…æ–¹tag
    parser.add_argument("--recipe_tag", default='cloudrobo_v1_l3mvn_all', help="æ•°æ®é…æ–¹æ ‡ç­¾")

    parser.add_argument("--gen_traj_method", default="l3mvn", help="è½¨è¿¹ç”Ÿæˆæ–¹æ³•: sp(shortest_path) or hd(human_demonstration) or l3mvn")
    parser.add_argument("--experiment_name", default="null", help="å®éªŒåç§°")

    # database connection parameters
    parser.add_argument("--db_user", default='dbadmin', help="æ•°æ®åº“ç”¨æˆ·å")
    parser.add_argument("--db_password", default='dataplatform@123', help="æ•°æ®åº“å¯†ç ")
    parser.add_argument("--db_host", default="dws-z00562901.dws.myhuaweiclouds.com", help="æ•°æ®åº“ä¸»æœº")
    parser.add_argument("--db_port", default="8000", help="æ•°æ®åº“ç«¯å£")
    parser.add_argument("--db_name", default='postgres' , help="æ•°æ®åº“åç§°")
    # force_overwrite å‚æ•°ï¼Œé»˜è®¤å€¼ä¸º False
    parser.add_argument("--force_overwrite", default='True' ,help="æ˜¯å¦å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„è®°å½•")

    args = parser.parse_args()
    invalid_args = precheck_args(args)
    if len(invalid_args) == 0:
        for arg, value in vars(args).items():
            print(f"ğŸ”§ å‚æ•° {arg}: {value}")
        main(args)
    elif len(invalid_args) > 0:
        for arg in invalid_args:
            print(f"âŒ å‚æ•° {arg} æ— æ•ˆï¼Œè¯·æ£€æŸ¥åé‡æ–°è¿è¡Œè„šæœ¬ã€‚")
        sys.exit(1)